{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420130ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/rachitverma/.local/lib/python3.8/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipywidgets) (8.12.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets) (4.6.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: backcall in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pickleshare in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: stack-data in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: decorator in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/rachitverma/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/rachitverma/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in /home/rachitverma/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/rachitverma/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/rachitverma/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/rachitverma/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.14.0)\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# pip install torch torchvision transformers pillow matplotlib\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2fc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an image is captioned as:\n",
    "\n",
    "# \"a man with eyeglasses reading a book\"\n",
    "# ‚Üí It gets sorted into the with_eyeglasses folder.\n",
    "\n",
    "# If it's:\n",
    "\n",
    "# \"a woman smiling\"\n",
    "# ‚Üí It goes to without_eyeglasses.\n",
    "\n",
    "import os # Imports necessary libraries for image processing, model loading, and visualization.\n",
    "import torch # PyTorch is used for deep learning tasks.\n",
    "from PIL import Image # Python Imaging Library for image processing.\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration #Loads a pre-trained AI model to describe what's in an image (caption generation).\n",
    "from tqdm.notebook import tqdm # tqdm is used for displaying progress bars in Jupyter notebooks.\n",
    "import shutil # shutil is used for file operations like copying files.\n",
    "import matplotlib.pyplot as plt # Matplotlib is used for image visualization.\n",
    "\n",
    "# AI captioning (BLIP) ‚Üí transformers, torch\n",
    "\n",
    "# Image handling ‚Üí PIL, shutil\n",
    "\n",
    "# Folder management ‚Üí os\n",
    "\n",
    "# Progress display ‚Üí tqdm\n",
    "\n",
    "# Visual output ‚Üí matplotlib\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Checks if a GPU is available and sets the device accordingly.\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\") # Loads the pre-trained model for image captioning.\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device) # Moves the model to the specified device (GPU or CPU).\n",
    "\n",
    "input_folder = \"images\" \n",
    "with_glasses_folder = \"with_eyeglasses\"\n",
    "without_glasses_folder = \"without_eyeglasses\"\n",
    "\n",
    "os.makedirs(with_glasses_folder, exist_ok=True) # Creates the folder for images with eyeglasses if it doesn't exist.\n",
    "os.makedirs(without_glasses_folder, exist_ok=True) # Creates the folder for images without eyeglasses if it doesn't exist.\n",
    "\n",
    "with_glasses_images = []\n",
    "\n",
    "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))] # Lists all image files in the input folder with specified extensions.\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"): # Displays a progress bar while processing images.\n",
    "    image_path = os.path.join(input_folder, filename) # Constructs the full path for each image file.\n",
    "    # Combines the folder name and file name into a full file path.\n",
    "    # Example: \"images\" + \"pic1.jpg\" ‚Üí \"images/pic1.jpg\"\n",
    "\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\") # Opens the image and converts it to RGB format.\n",
    "    # **Opens the image** file.\n",
    "    # - Converts it to **RGB color format** (3 color channels ‚Äî Red, Green, Blue) so the model can understand it.\n",
    "\n",
    "\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device) # Prepares the image for the model by processing it and converting it to a tensor.\n",
    "    \n",
    "    # from for filename in tqdm upto inputs => Simple flow - üìÅ image ‚Üí üñº open & convert ‚Üí üß™ process ‚Üí üß† send to model (on CPU/GPU)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad(): # Disables gradient calculation for inference to save memory and computation.\n",
    "      #  Tells PyTorch:\n",
    "      # ‚ÄúI‚Äôm only using the model, not training it.‚Äù\n",
    "\n",
    "      # Saves memory and speeds things up.\n",
    "      \n",
    "      out = model.generate(**inputs) # Generates a caption for the image using the model.\n",
    "      caption = processor.decode(out[0], skip_special_tokens=True).lower() # Decodes the generated caption and converts it to lowercase.\n",
    "      # Converts the model‚Äôs output (token IDs) into a readable string.\n",
    "\n",
    "      # Example:\n",
    "      # Output: [101, 1037, 2158, 2084, 3899, 102]\n",
    "      # Becomes: \"a man with glasses\"\n",
    "\n",
    "\n",
    "    print(f\"{filename}: Caption = {caption}\") # Prints the filename and its generated caption.\n",
    "\n",
    "    if any(word in caption for word in [\"eyeglasses\", \"glasses\", \"spectacles\"]): # Checks if the caption contains any keywords indicating the presence of eyeglasses.\n",
    "        shutil.copy(image_path, os.path.join(with_glasses_folder, filename)) # Copies the image to the folder for images with eyeglasses.\n",
    "        with_glasses_images.append(image_path) # Appends the image path to the list of images with eyeglasses.\n",
    "    else:\n",
    "        shutil.copy(image_path, os.path.join(without_glasses_folder, filename)) #Copies the image into the correct folder.\n",
    "\n",
    "def show_images(image_paths, title): \n",
    "    plt.figure(figsize=(12, 6)) # Sets up a figure for displaying images.\n",
    "    plt.suptitle(title, fontsize=16) # Sets the title for the figure.\n",
    "    for i, path in enumerate(image_paths[:6]): # Loops through the first 6 images to display.\n",
    "        img = Image.open(path) # Opens each image file.\n",
    "        plt.subplot(2, 3, i + 1) # Creates a subplot for each image.\n",
    "        plt.imshow(img) # Displays the image.\n",
    "        plt.title(os.path.basename(path)) # Sets the title for each subplot to the image filename.\n",
    "        plt.axis('off') # Turns off the axis for a cleaner look.\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "if with_glasses_images:\n",
    "    show_images(with_glasses_images, \"Images with Eyeglasses\")\n",
    "else:\n",
    "    print(\"No eyeglasses detected in images.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ffa05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6613e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
